{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "83841a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from icecream import ic\n",
    "import json\n",
    "from datetime import datetime\n",
    "from copy import deepcopy\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c869eb9a",
   "metadata": {},
   "source": [
    "## load variables - contours\n",
    "- data folder\n",
    "- cleaned_df - for only contours\n",
    "- json template\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0887a01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/victor/Documents/projects/mini_projects/regreen_cleaning/brics3_migration\n"
     ]
    }
   ],
   "source": [
    "cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a0ad9978",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = os.path.join(os.getcwd(),'data')\n",
    "cleaned_csv = os.path.join(data_folder, 'final_range_data.csv')\n",
    "dff = pd.read_csv(cleaned_csv)\n",
    "\n",
    "#lambda function to filter for contours\n",
    "#for each row, is it a list/str, then is 'contours' in it, if so, return the df.\n",
    "cleaned_df = dff[\n",
    "    dff[\"land_use_selection-intervention\"]\n",
    "    .apply(lambda x: isinstance(x, (list, str)) and \"contour_planting\" in x)\n",
    "]\n",
    "\n",
    "#contours datasets\n",
    "contours_df = pd.read_csv(os.path.join(data_folder, 'brics_csvs', 'outputs','cleaned_Rangeland_Somalia_BRCiSIII-trees_grasses_contour.csv'))\n",
    "\n",
    "TEMPLATE_FILE = os.path.join(data_folder,\"halfmoon_json_template.json\")\n",
    "with open(TEMPLATE_FILE, \"r\") as f:\n",
    "    template = json.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f95ba71",
   "metadata": {},
   "source": [
    "## check contours count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "fbf80b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mcontours count\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;32mlen\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mcleaned_df\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m9\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('contours count', 9)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = dff[\"land_use_selection-intervention\"]\n",
    "count = 0\n",
    "for idx, i in enumerate(list(x)):\n",
    "    if 'contour_planting' in i:\n",
    "        count += 1\n",
    "        #ic(i, count)\n",
    "\n",
    "ic('contours count',len(cleaned_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a5dc4a",
   "metadata": {},
   "source": [
    "## enumerators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "71d76cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorted(list(dff['basic_info-name'].unique()))\n",
    "##empty name and key dictionary\n",
    "names_dict = {}\n",
    "for idx, row in dff.iterrows():\n",
    "    #ic({row[\"KEY\"], row[\"basic_info-name\"]})\n",
    "    names_dict[row[\"KEY\"]] = row[\"basic_info-name\"]\n",
    "#ic(names_dict)\n",
    "name_uname_dict = {\n",
    "    \"Zakariye haji ali\": \"abdullahi.hassan@mardo.org\", \n",
    "    \"Issack Idow Ibrahim\": \"abdullahi.hassan@mardo.org\",\n",
    "    \"Abdullahi Hassan Adan\": \"abdullahi.hassan@mardo.org\",\n",
    "    \"Abdikheir Mohamed\": \"mukhtar.yusuf23\",\n",
    "    \"Abdikheir Mohamed Ali\": \"mukhtar.yusuf23\",\n",
    "    \"Abdikheir Mohamed Dahir\": \"mukhtar.yusuf23\",\n",
    "    \"Ali\": \"mukhtar.yusuf23\",\n",
    "    \"Ali Adan\": \"mukhtar.yusuf23\",\n",
    "    \"Ali Aden\": \"mukhtar.yusuf23\",\n",
    "    \"Fathi\": \"mukhtar.yusuf23\", \n",
    "    \"Fathi Abdirashid\": \"mukhtar.yusuf23\",\n",
    "    \"Ahmed Omar Hassan\": \"AhmedOmar\",\n",
    "    \"Maria Abdirahman Ali\": \"AhmedOmar\",\n",
    "    \"ABSHIR ABDULLAH ALI\": \"Ahil\",\n",
    "    \"Ahmed Ibrahim\": \"JubaFoundation\",\n",
    "    \"Ahmed Ibrahim Mohamed\": \"JubaFoundation\",\n",
    "    \"Abdiaziz Adan Hassa\": \"guudow\",\n",
    "    \"Abdiaziz Adan Hassan\": \"guudow\",\n",
    "    \"Abdi Hassan Adan\": \"AbdiHassan\",\n",
    "    \"Abdullahi\": \"sharif1234\",\n",
    "    \"Abdirashid Sheikh Mohamed\": \"NRMO\",\n",
    "    \"Abdullahi Sharif\": \"sharif1234\",\n",
    "    \"Abdullahi Sharif LLG\": \"sharif1234\",\n",
    "    \"Abdullahi Sharif Noor LLG\": \"sharif1234\",\n",
    "    \"Abdijalil\": \"Csxaashi\",\n",
    "    \"Abdijalil said\": \"Csxaashi\",\n",
    "    \"Abdikarim Mohamed Ismail\": \"samandoulgou\",\n",
    "    \"Abdikarin Mohamed Ismail\": \"samandoulgou\",\n",
    "    \"Hassan Omar Khadhib\": \"Khadhib\",\n",
    "    \"Hassan Omar Khadhibr\": \"Khadhib\",\n",
    "    \"Jamal Ali\": \"JamalAli\",\n",
    "    \"Jamal Ali Tagal\": \"JamalAli\",\n",
    "    \"Mohamud Abdullahi Ali\": \"Mohamud\",\n",
    "    \"Moulid Abdullahi Abdi\": \"Moulidwadani\",\n",
    "    \"Muktar Mohamednoor Rage\": \"Mrage1997\",\n",
    "    \"Osman Ebey Omar\": \"iibey\",\n",
    "    \"Yusuf Mahi munye\": \"Mcnbdn617660\",\n",
    "    \"abdullahi Sharif LLG\": \"sharif1234\",\n",
    "    \"osman Ebey Omar\": \"iibey\",\n",
    "}\n",
    "\n",
    "## match and replace names with usernames\n",
    "for k, v in names_dict.items():\n",
    "    for key, value in name_uname_dict.items():\n",
    "        if v == key:\n",
    "            names_dict[k] = value\n",
    "#ic(names_dict)\n",
    "\n",
    "##enumerator dictionary\n",
    "enumerator = {\n",
    "        \"id\": 3726,\n",
    "        \"first_name\": \"First\",\n",
    "        \"last_name\": \"Last\",\n",
    "        \"gender\": \"Male\",\n",
    "        \"age_category\": \"18 - 35\",\n",
    "        \"phone_number\": \"0e15704046\",\n",
    "        \"email\": \"test_mail@gmail.com\",\n",
    "        \"country\": \"test\",\n",
    "        \"organization\": \"Test\",\n",
    "        \"username\": \"test\",\n",
    "        \"type\": \"ENUMERATOR\"\n",
    "    }\n",
    "\n",
    "enums = []\n",
    "#create enumerator jsons\n",
    "for key, value in names_dict.items():\n",
    "    e = deepcopy(enumerator)\n",
    "    e['username'] = value\n",
    "    e['key'] = key\n",
    "    enums.append(e)\n",
    "\n",
    "#ic(enums)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da68f60",
   "metadata": {},
   "source": [
    "## farming entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e301e767",
   "metadata": {},
   "outputs": [],
   "source": [
    "farming_entity_list = []\n",
    "for idx, i in enumerate(cleaned_df.to_dict(orient='records'), start=1):\n",
    "    farming_entity = {}\n",
    "    #ic(i['basic_info-organisation_name'])\n",
    "    farming_entity['id'] = idx\n",
    "    farming_entity['first_name'] = i['basic_info-organisation_name']\n",
    "    farming_entity['middle_name'] = i['basic_info-organisation_name']\n",
    "    farming_entity['last_name'] = i['basic_info-organisation_name']\n",
    "    farming_entity['organization'] = 'INSTITUTION'\n",
    "    farming_entity['key'] = i['KEY']\n",
    "    \n",
    "    farming_entity_list.append(\n",
    "        {\n",
    "            \"farmingEntity\": farming_entity, \n",
    "            'key': i['KEY']\n",
    "        }\n",
    "    )\n",
    "    #ic(farming_entity_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7eb6115",
   "metadata": {},
   "source": [
    "## plot-contours_details\n",
    "- read df to dictionary, for matching keys, extract df values\n",
    "### plot-points\n",
    "- parse the geoshape column from cleaned df\n",
    "- split and extract the values from each i\n",
    "- append to json keys\n",
    "\n",
    "## crops\n",
    "- get matching rows based on key(id)\n",
    "- for these rows if crop has crops, get its values and 'other' if any\n",
    "    - every matching rows values are appended to a list(of all crops for that plot)\n",
    "- clean 'and' from the crop types\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "5287b4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mcrop_list\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36msugarcane\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mmaize\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36msorghum\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mbeans\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mbanana\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mdate\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m]\u001b[39m\n",
      "\u001b[38;5;245m    \u001b[39m\u001b[38;5;247mx\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mKEY\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36muuid:c9db5e91-ee4d-4098-92ca-1551e55a6c28/contour/trees_grasses_contour[1]\u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mcrop_list\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36msugarcane\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mmaize\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mbeans\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mbanana\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36morange\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mdate\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m]\u001b[39m\n",
      "\u001b[38;5;245m    \u001b[39m\u001b[38;5;247mx\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mKEY\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36muuid:c9db5e91-ee4d-4098-92ca-1551e55a6c28/contour/trees_grasses_contour[2]\u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mcrop_list\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mmaize\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36msugarcane\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mbanana\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mdate\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mtomato\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m]\u001b[39m\n",
      "\u001b[38;5;245m    \u001b[39m\u001b[38;5;247mx\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mKEY\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36muuid:c9db5e91-ee4d-4098-92ca-1551e55a6c28/contour/trees_grasses_contour[3]\u001b[39m\u001b[38;5;36m'\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "import copy\n",
    "import re\n",
    "\n",
    "plot_list = []\n",
    "point_id = 1\n",
    "\n",
    "records = cleaned_df.to_dict(orient='records')\n",
    "\n",
    "count = 0\n",
    "#iterate over every i to capture plot details\n",
    "for idx, i in enumerate(records):\n",
    "    plot_id = idx + 1\n",
    "    count += 1\n",
    "\n",
    "    # ---- BUILD PLOT DETAILS ----\n",
    "    template_cp = copy.deepcopy(template[0])\n",
    "    plot_details = template_cp['plot']\n",
    "\n",
    "    plot_details['id'] = plot_id\n",
    "    plot_details['key'] = i['KEY']\n",
    "    plot_details['name'] = uuid.uuid4().hex\n",
    "    plot_details['calculated_size'] = i['area_ha']\n",
    "    plot_details['photo_url'] = i['plot_details-photo']\n",
    "    plot_details['farmingEntityId'] = farming_entity['id']\n",
    "    plot_details['livestock_allowed'] = False if i['land_use_selection-land_use'] == 'agriculture' else True\n",
    "    plot_details['conservation_area'] = False\n",
    "\n",
    "    #get only child row for this key\n",
    "    matching_child_rows = contours_df[contours_df['PARENT_KEY'] == i['KEY']]\n",
    "\n",
    "    #holds every row's crops\n",
    "    all_crops = []\n",
    "    \"\"\"----------------------------------CROP STATUS ----------------------------------\"\"\"\n",
    "    #iterate over matching child is to build crop status\n",
    "    for x in pd.DataFrame(matching_child_rows).to_dict(orient='records'):\n",
    "        #ic(x['PARENT_KEY'], x[\"KEY\"], x[\"managements_contourcrops_in_field2\"], x[\"managements_contour-other_crops\"])\n",
    "\n",
    "        if x['managements_contour-crops_present5'] == 'no' or pd.isna(x['managements_contour-crops_present5']):\n",
    "            plot_details['has_crops'] = False\n",
    "        elif x['managements_contour-crops_present5'] == 'yes':\n",
    "            plot_details['has_crops'] = True\n",
    "\n",
    "\n",
    "        #get a list of all crops in field\n",
    "        if pd.isna(x['managements_contour-crops_in_field5']):\n",
    "            crop_list = []\n",
    "        else:\n",
    "            crop_list = str(x['managements_contour-crops_in_field5']).split(\" \")\n",
    "            ic(crop_list, x['KEY'])\n",
    "\n",
    "\n",
    "        #check that 'other' crops exist\n",
    "        if 'other' in crop_list:\n",
    "            #split by comma or 'and'\n",
    "            other_crops_value = re.split(r',|\\band\\b', x['managements_contour-other_crops'])\n",
    "            #strip whitespace\n",
    "            other_crops_value = [c.strip() for c in other_crops_value if c.strip()]\n",
    "\n",
    "            #get rid of 'and' if exists\n",
    "            if 'and' in other_crops_value:\n",
    "                other_crops_value.remove('and')\n",
    "\n",
    "            #only add if not empty\n",
    "            if other_crops_value != []:\n",
    "                crop_list.remove('other')\n",
    "                crop_list.extend(other_crops_value)\n",
    "                #append crop list for this row to all crops\n",
    "            all_crops.extend(crop_list)\n",
    "            ic(all_crops)\n",
    "        \n",
    "        elif 'other' not in crop_list:\n",
    "            all_crops.extend(crop_list)\n",
    "\n",
    "        plot_details['crops'] = list(set(all_crops))\n",
    "\n",
    "        \n",
    "    \"\"\"--------------------------------GEOSHAPE PARSING ----------------------------------\"\"\"\n",
    "    geoshape_str = i['plot_details-polygon']\n",
    "    \n",
    "    def parse_geoshape(geoshape_str):\n",
    "        #parse a geoshape string into a list of point dictionaries\n",
    "        points = []\n",
    "        parts = geoshape_str.split(';')\n",
    "\n",
    "        for part in parts:\n",
    "            part = part.strip()\n",
    "            if not part:\n",
    "                continue\n",
    "\n",
    "            lat, lon, alt, acc = map(float, part.split(' '))\n",
    "\n",
    "            points.append({\n",
    "                \"longitude\": lon,\n",
    "                \"latitude\": lat,\n",
    "                \"altitude\": alt,\n",
    "                \"accuracy\": acc\n",
    "            })\n",
    "\n",
    "        return points\n",
    "\n",
    "    parsed_points = parse_geoshape(geoshape_str)\n",
    "\n",
    "    points_list = []\n",
    "    for p in parsed_points:\n",
    "        points_list.append({\n",
    "            \"id\": point_id,\n",
    "            \"plotId\": plot_id,\n",
    "            \"longitude\": p[\"longitude\"],\n",
    "            \"latitude\": p[\"latitude\"],\n",
    "            \"altitude\": p[\"altitude\"],\n",
    "            \"accuracy\": p[\"accuracy\"]\n",
    "        })\n",
    "        point_id += 1\n",
    "\n",
    "\n",
    "    \"\"\"--------------------------------ADMINISTRATIVE DETAILS ----------------------------------\"\"\"\n",
    "    administrative = plot_details['subCounty']\n",
    "    administrative['subcounty_name'] = i['geography-district_name']\n",
    "    administrative['county']['county_name'] = i['geography-region_name']\n",
    "\n",
    "\n",
    "    #update plot_details with number of points and administrative info\n",
    "    plot_details['points'] = points_list\n",
    "    plot_details['subCounty'] = administrative\n",
    "    \n",
    "    # del plot_details['points']\n",
    "    # del plot_details['subCounty']\n",
    "    general_plot = {\n",
    "        \"plot\":plot_details, \n",
    "        'key':i['KEY']\n",
    "    }\n",
    "    #ic(i['KEY'])\n",
    "    plot_list.append(\n",
    "        general_plot\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "71476929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nan']"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(os.path.join(data_folder, 'to_delete.json'), 'w') as f:\n",
    "    json.dump(plot_list, f, indent=4)\n",
    "\n",
    "str(contours_df['managements_contour-crops_in_field5'][0]).split(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e71578",
   "metadata": {},
   "source": [
    "# project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "f954309b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;32mset\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mnames\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;245m{\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mRAF\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mbrcis3\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m}\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'RAF', 'brcis3'}"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projects_list = []\n",
    "\n",
    "names =[]\n",
    "for row in cleaned_df.to_dict(orient='records'):\n",
    "    name = row['land_use_selection-project_name']\n",
    "    names.extend([name])\n",
    "\n",
    "    if name == 'terra':\n",
    "        name = name.upper()\n",
    "        id = 131\n",
    "    elif name == 'brcis3':\n",
    "        name = 'BRCiS III'\n",
    "        id = 93\n",
    "\n",
    "    projects_list.append({\n",
    "        \"project\": {\n",
    "            \"id\": id,\n",
    "            \"project_name\": name\n",
    "        },\n",
    "        \"key\": row['KEY']\n",
    "    })\n",
    "\n",
    "ic(set(names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e80c247",
   "metadata": {},
   "source": [
    "## contours \n",
    "missing \n",
    "- herbacious cover\n",
    "- who manages >> used who established\n",
    "- erosion type\n",
    "- is_intervention_effective\n",
    "- vertical_spacing\n",
    "- horizontal_spacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "3c90dba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtrees_species_list\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mother\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m]\u001b[39m\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"int\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[155]\u001b[39m\u001b[32m, line 72\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;66;03m#handle nan cases\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m local_name != \u001b[33m'\u001b[39m\u001b[33mnan\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m local_name != \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m     \u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m     73\u001b[39m     tree_current_status = {\n\u001b[32m     74\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m: idxx + \u001b[32m1\u001b[39m,\n\u001b[32m     75\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mlocal_name\u001b[39m\u001b[33m\"\u001b[39m: local_name.capitalize(),\n\u001b[32m     76\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mscientific_name\u001b[39m\u001b[33m\"\u001b[39m: scientific_name,\n\u001b[32m     77\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mecontrol_status_id\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m1\u001b[39m\n\u001b[32m     78\u001b[39m     }\n\u001b[32m     79\u001b[39m     ic(tree_current_status)\n",
      "\u001b[31mTypeError\u001b[39m: can only concatenate str (not \"int\") to str"
     ]
    }
   ],
   "source": [
    "contours_list = []\n",
    "\n",
    "#dictionary to map odk values to RA app schema values\n",
    "mapping_dict = {\n",
    "    \"STICKS_BRANCH\":\"STICKS_PROTECTION\",\n",
    "    \"DEBRIS_REMOVAL\":\"DEBRIS_REMOVAL\",\n",
    "    \"INVASIVE_SPECIES\":\"INVASIVE_CONTROL\",\n",
    "    \"WEEDING\":\"WEEDING\",\n",
    "    \"WATERING\":\"WATERING\",\n",
    "    \"PLANTING_SEEDLING\":\"PLANTING_ANNUAL_PERENNIAL_CROPS\"\n",
    "}\n",
    "\n",
    "\n",
    "for idx, c in enumerate(records):\n",
    "\n",
    "    cureent_status_list = []\n",
    "    all_grasses = []\n",
    "    all_trees = []\n",
    "\n",
    "    #if c['KEY'] == \"uuid:1975a725-83a5-4bdd-8305-35ac65b2cce9\":\n",
    "    \"\"\"-----------------------------------contours CHILD DETAILS-------------------------------------\"\"\"\n",
    "\n",
    "    total_num_grasses_planted = 0\n",
    "    total_kg_grass_seeds = 0.0\n",
    "    total_num_tree_species = 0\n",
    "    total_num_trees_planted = 0\n",
    "    total_num_trees_survived = 0\n",
    "    grass_present = []\n",
    "    trees_present = []\n",
    "    mngmts = []\n",
    "    \n",
    "    #for every record, get the matching child rows\n",
    "    matching_child_rows = contours_df[contours_df['PARENT_KEY'] == c['KEY']]\n",
    "    #matching_child_rows = contours_df[contours_df['PARENT_KEY'] == \"uuid:91755b0a-6073-4d6d-88a8-55eaa382d3e6\"]\n",
    "    idxx =0\n",
    "    for x in matching_child_rows.to_dict(orient='records'):\n",
    "\n",
    "        total_num_grasses_planted += 0 if pd.isna(x[\"grass_contour-num_grass_species\"]) else x[\"grass_contour-num_grass_species\"]\n",
    "        total_kg_grass_seeds += 0 if pd.isna(x[\"grass_contour-kg_grass_seeds\"]) else x[\"grass_contour-kg_grass_seeds\"]\n",
    "        total_num_tree_species += 0 if pd.isna(x[\"tree_contour-num_tree_species\"]) else x[\"tree_contour-num_tree_species\"]\n",
    "        total_num_trees_planted += 0 if pd.isna(x[\"tree_contour-num_trees_planted\"]) else x[\"tree_contour-num_trees_planted\"]\n",
    "        total_num_trees_survived += 0 if pd.isna(x[\"tree_contour-num_tree_survived\"]) else x[\"tree_contour-num_tree_survived\"]\n",
    "        grass_present.append(True if str(x[\"tree_contour-planted_choice5\"]).strip() in [\"both\", \"grasses\"] else False)\n",
    "        trees_present.append(True if str(x[\"tree_contour-planted_choice5\"]).strip() in [\"both\", \"trees\"] else False)\n",
    "        mngmts.extend(str(x[\"managements_contour-management_practices\"]).upper().split()) if not pd.isna(x[\"managements_contour-management_practices\"]) else 'NAN'\n",
    "\n",
    "        \"\"\"--------------TREE ESTABLISHMENT-------------\"\"\"\n",
    "        tree_status_list = []\n",
    "        if x['tree_contour-planted_choice5'] in [\"both\", \"trees\"]:\n",
    "            trees_species_list = x[\"tree_contour-contour_trees_species\"].split()\n",
    "            ic(trees_species_list)\n",
    "            j = 0 \n",
    "            for idx3, raw in enumerate(trees_species_list):\n",
    "                #ic(\"original\",raw)\n",
    "                #default\n",
    "                scientific_name = \"\"\n",
    "                local_name = \"\"\n",
    "                \n",
    "                #case1: check or other in the tree species list\n",
    "                if raw == 'other':\n",
    "                    #ic(\"other\",raw)\n",
    "                    other_val = str(x[\"tree_contour-other_contour_trees\"]).strip()\n",
    "                    #ic(\"other_val\", other_val)\n",
    "\n",
    "                    #split by comma & 'and'\n",
    "                    names = re.split(r\",| and \", other_val, flags=re.IGNORECASE)\n",
    "                    #ic(names)\n",
    "                    for idxx, val in enumerate(names):\n",
    "                        local_name = val.strip()\n",
    "                        #handle nan cases\n",
    "                        if local_name != 'nan' and local_name != \"\":\n",
    "                            k += 1\n",
    "                            tree_current_status = {\n",
    "                                \"id\": idxx + 1,\n",
    "                                \"local_name\": local_name.capitalize(),\n",
    "                                \"scientific_name\": scientific_name,\n",
    "                                \"econtrol_status_id\": 1\n",
    "                            }\n",
    "                            ic(tree_current_status)\n",
    "                            tree_status_list.append(tree_current_status)\n",
    "\n",
    "                #case 2: scientific + local name extraction\n",
    "                if \"(\" in raw and \")\" in raw:\n",
    "                    #scientific name cleaning\n",
    "                    parts = raw.split(\"(\")[0].strip().replace(\"_\", \" \").split()\n",
    "                    #ic(parts)\n",
    "                    if len(parts) >= 2:\n",
    "                        scientific_name = f\"{parts[0].capitalize()} {parts[1].lower()}\"\n",
    "                        #ic(scientific_name)\n",
    "\n",
    "                    #local name cleaning\n",
    "                    paarts = raw.split(\"(\")[1].split(\")\")[0].strip().replace(\"_\", \" \").replace(\",\", \" \").split()\n",
    "                    #ic(paarts)\n",
    "                    if len(paarts) >= 2:\n",
    "                        local_name = f\"{paarts[0].capitalize()} {paarts[1].lower()}\"\n",
    "                        #ic(local_name)\n",
    "                    else:\n",
    "                        local_name = paarts[0].capitalize()\n",
    "                        #ic(local_name)\n",
    "\n",
    "\n",
    "        all_trees.extend(tree_status_list)\n",
    "        #ic(all_trees)\n",
    "\n",
    "        grass_status_list = []\n",
    "        \"\"\"---------------GRASS_ESTABLISHMENT------------\"\"\"\n",
    "        #get all grasses \n",
    "        if x[\"tree_contour-planted_choice5\"] in [\"both\", \"grasses\"]:\n",
    "            grass_species_list = str(x[\"grass_contour-contour_grass_species\"]).split()\n",
    "            #default\n",
    "            scientific_name = \"\"\n",
    "            local_name = \"\"\n",
    "\n",
    "            for idx2 ,raw in enumerate(grass_species_list):\n",
    "                #case 1: others\n",
    "                if raw.strip() == 'other':\n",
    "                    other_raw = str(x[\"grass_contour-other_contours_grass\"])\n",
    "\n",
    "                    #split by comma & 'and'\n",
    "                    names = re.split(r\",| and \", other_raw, flags=re.IGNORECASE)\n",
    "\n",
    "                    #loop through local names\n",
    "                    for idx, name in enumerate(names):\n",
    "                        cleaned = name.strip()\n",
    "                        if cleaned != 'nan':\n",
    "                            grass_current_status_1 = ({\n",
    "                                \"id\": idx + 1,\n",
    "                                \"local_name\": cleaned,\n",
    "                                \"scientific_name\": \"\",\n",
    "                                \"econtrol_status_id\": 1\n",
    "                            })\n",
    "                        grass_status_list.append(grass_current_status_1)\n",
    "\n",
    "                    continue\n",
    "                \n",
    "                #case2: ends with other and also has nan in other colun\n",
    "                elif raw.strip().endswith('other'):\n",
    "                    #use the 'other' column\n",
    "                    local_name = str(j['halfmoon_grasses-other_halfmoon_grass']).strip()\n",
    "                #case 3: split local name from scientific name\n",
    "                else:\n",
    "                    #split scientific and local names\n",
    "                    if \"(\" in raw and \")\" in raw:\n",
    "                        #scientific name cleaning\n",
    "                        parts = raw.split(\"(\")[0].strip().replace(\"_\", \" \").split()\n",
    "                        if len(parts) == 2:\n",
    "                            scientific_name = f\"{parts[0].capitalize()} {parts[1].lower()}\"\n",
    "                        else:\n",
    "                            scientific_name = raw.split(\"(\")[0].strip().replace(\"_\", \" \")\n",
    "\n",
    "                        #local name cleaning\n",
    "                        paarts = raw.split(\"(\")[1].split(\")\")[0].strip().replace(\"_\", \" \").split()\n",
    "                        if len(paarts) == 2:\n",
    "                            local_name = f\"{paarts[0].capitalize()} {paarts[1].lower()}\"\n",
    "                        else:\n",
    "                            local_name = raw.split(\"(\")[1].split(\")\")[0].strip().replace(\"_\", \" \").replace(\",\", \" \")#[1].lower()\n",
    "                    else:\n",
    "                        scientific_name = raw.strip()\n",
    "\n",
    "                if local_name != 'nan':\n",
    "                    grass_current_status = {\n",
    "                        \"id\": idx2 + 1,\n",
    "                        \"local_name\": local_name,\n",
    "                        \"scientific_name\": scientific_name,\n",
    "                        \"econtrol_status_id\": 1\n",
    "                    }\n",
    "            \n",
    "                #append the current status for ths record to the empty list\n",
    "                grass_status_list.append(grass_current_status)\n",
    "        \n",
    "        \"\"\"--------------------CURRENT STATUS--------------------\"\"\"\n",
    "        idxx += 1\n",
    "        currentStatus= {\n",
    "            \"id\": idxx,\n",
    "            \"key\":c[\"KEY\"],            \n",
    "            \"herbaceous_cover\": \"\",\n",
    "            \"visible_erosion\": True,\n",
    "            \"erosion_type\": [\n",
    "                \"OTHER\"\n",
    "            ],\n",
    "            \"other_erosion_type\": \"NONE\",\n",
    "            \"is_intervention_effective\": True,\n",
    "            \"longitude\": x[\"gps-Longitude\"],\n",
    "            \"latitude\": x[\"gps-Latitude\"],\n",
    "            \"altitude\": x[\"gps-Altitude\"],\n",
    "            \"accuracy\": x[\"gps-Accuracy\"],\n",
    "            \"photo_url\": x[\"photo\"],\n",
    "            \"comments\": f\"agric_field_state {x[\"managements_contour-agricultural_field_state\"] if pd.notna(x[\"managements_contour-agricultural_field_state\"]) else \"MIGRATED_NOT_KNOWN\"} state {c[\"geography-state_name\"].replace(\"â€¦\", \"\").replace(\".\", \"\").replace(\"..\", \"\")} community {c['geography-community_name']}\",\n",
    "            \"econtrolId\": 1,\n",
    "            \"grassCurrentStatus\":grass_status_list,\n",
    "            \"treeCurrentStatus\":tree_status_list\n",
    "        }\n",
    "        \n",
    "        #add every status to the to serve as establishment        \n",
    "        all_grasses.extend(grass_status_list)\n",
    "\n",
    "        cureent_status_list.append(currentStatus)\n",
    "\n",
    "\n",
    "    \"\"\"-----------------------------------contours DETAILS-------------------------------------\"\"\"\n",
    "\n",
    "    contours_details = {\n",
    "        \"id\": idx + 1,\n",
    "        \"key\":c[\"KEY\"],\n",
    "        \"erosion_control_type\": \"Contours\",\n",
    "        \"established_date\": datetime.strptime(c['contour-contour_details-date'], \"%d/%m/%Y\").strftime(\"%Y-%m\"),\n",
    "        \"material_used\": [\n",
    "            \"OTHER\"\n",
    "        ],\n",
    "        \"other_material_used\": \"MIGRATED_NOT_KNOWN\",\n",
    "        \"who_established\": [\"MALE\", \"FEMALE\"] if c[\"contour-contour_details-manages\"] == 'both' else \"MALE\" if c[\"contour-contour_details-manages\"]==\"male\" else \"\",\n",
    "        \"other_who_established\": \"YOUTH\" if c[\"contour-contour_details-youth_manages\"] == 'yes' else \"\",\n",
    "        \"total_interventions\": c[\"contour-contour_details-total\"],\n",
    "        \"length\": c[\"contour-contour_details-length\"],\n",
    "        \"width\": c[\"contour-contour_details-width\"],\n",
    "        \"depth\": c[\"contour-contour_details-depth\"],\n",
    "        \"vertical_spacing\": 0,\n",
    "        \"horizontal_spacing\": 0,\n",
    "        \"labor_payment\": c[\"contour-contour_details-paid_unpaid_labor\"],        \n",
    "        \"has_grass\": any(grass_present),\n",
    "        \"total_number_grasses_planted\": total_num_grasses_planted,\n",
    "        \"kg_grass_seeds_planted\": total_kg_grass_seeds,\n",
    "        \"has_trees\": any(trees_present),\n",
    "        \"total_number_different_trees_planted\": total_num_tree_species,\n",
    "        \"total_number_trees_planted\": total_num_trees_planted,\n",
    "        \"total_number_trees_survived\": total_num_trees_survived,\n",
    "        \"management_practices\":  [v for k, v in mapping_dict.items() if k in mngmts] + ([\"OTHER\"] if any(k not in mapping_dict.keys() for k in mngmts) else []),\n",
    "        \"other_managements\": \" \".join([c for c in mngmts if c not in mapping_dict.keys()]),\n",
    "        \"usages\":[\"MIGRATED_NOT_KNOWN\"],\n",
    "        \"other_usages\": \"\",\n",
    "        \"rangelandEntryId\": 2,\n",
    "        \"currentStatus\": cureent_status_list,\n",
    "        \"grassEstablishment\": all_grasses,\n",
    "        \"treeEstablishment\":all_trees   \n",
    "    }\n",
    "\n",
    "    contours_list.append(contours_details)\n",
    "    \n",
    "\n",
    "\n",
    "contours_econtrol = [{\"econtrol\": [i], \"key\" :i[\"key\"]} for i in contours_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "724ce518",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_folder, 'to_delete.json'), 'w') as f:\n",
    "    json.dump(contours_econtrol, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a722111c",
   "metadata": {},
   "source": [
    "## merge components into one json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "54d76732",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;32mlen\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mlst\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m9\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;32mlen\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mlst\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m9\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;32mlen\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mlst\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m9\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;32mlen\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mlst\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m9\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;32mlen\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mfinal\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m9\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# component lists\n",
    "lists = [farming_entity_list, contours_econtrol, plot_list, projects_list]\n",
    "\n",
    "# The output dictionary\n",
    "merged = {}\n",
    "\n",
    "for lst in lists:\n",
    "    ic(len(lst))\n",
    "    for item in lst:\n",
    "        k = item['key']\n",
    "\n",
    "        #check if already updated\n",
    "        if k not in merged:\n",
    "            merged[k] = {}\n",
    "            \n",
    "        #merge the item into the existing dictionary\n",
    "        merged[k].update(item)\n",
    "\n",
    "final = list(merged.values())\n",
    "for i in final:\n",
    "    #match enumerators\n",
    "    for l in enums:\n",
    "        if i['key'] == l['key']:\n",
    "            i['enumerator'] = l\n",
    "\n",
    "\n",
    "    i[\"boma\"] = []\n",
    "    i[\"cgrazing\"] = []\n",
    "    i[\"microcatchment\"]= []\n",
    "    i[\"seedbank\"] = []\n",
    "    i[\"seeding\"] = []\n",
    "    i[\"waterpoint\"] = []\n",
    "    i[\"completed\"] = True\n",
    "    i[\"rangeModuleId\"] = 1\n",
    "    i[\"currentStep\"]= \"DONE\"\n",
    "    i[\"moduleId\"] = 6\n",
    "    i[\"is_revisit\"] = False\n",
    "    #get the date_collected\n",
    "    for j in records:\n",
    "        if i[\"key\"] == j[\"KEY\"]:\n",
    "            i[\"date_collected\"] = datetime.strptime(j['basic_info-date'], \"%d/%m/%Y\").strftime(\"%Y-%m-%d\")\n",
    "    #match project id\n",
    "    for x in projects_list:\n",
    "        if i['key'] == x['key']:\n",
    "            i['projectId'] = x['project']['id']\n",
    "    #match plot id\n",
    "    for k in plot_list:\n",
    "        if i['key'] == k['key']:\n",
    "            i['plotId'] = k['plot']['id']\n",
    "    #match farming_entity_id\n",
    "    for h in farming_entity_list:\n",
    "        if i['key'] == h['key']:\n",
    "            i['farmingEntityId'] = h['farmingEntity']['id']\n",
    "    #match enumerator id\n",
    "    for e in enums:\n",
    "        if i['key'] == e['key']:\n",
    "            i['enumeratorId'] = e['id']\n",
    "\n",
    "\n",
    "ic(len(final))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "5f30fb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_folder, 'to_delete.json'), 'w') as f:\n",
    "    json.dump(final, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46b4ad0",
   "metadata": {},
   "source": [
    "## clean up keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "c560868f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean up keys\n",
    "def remove_keys(obj, key=\"key\"):\n",
    "    if isinstance(obj, dict):\n",
    "        obj.pop(key, None)\n",
    "        for v in obj.values():\n",
    "            remove_keys(v, key)\n",
    "    elif isinstance(obj, list):\n",
    "        for v in obj:\n",
    "            remove_keys(v, key)\n",
    "    return obj\n",
    "\n",
    "finaal = [x for x in final if x['key'] == 'uuid:b4a2d545-66fe-4d23-825b-41025149b460']\n",
    "finaal = [remove_keys(i) for i in final]\n",
    "\n",
    "#add id\n",
    "for idx, c in enumerate(finaal):\n",
    "    c['id'] = idx + 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "083dcee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_folder, 'to_delete.json'), 'w') as f:\n",
    "    json.dump(finaal, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
