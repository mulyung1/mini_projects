{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eea8720b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from icecream import ic\n",
    "import json\n",
    "from datetime import datetime\n",
    "from copy import deepcopy\n",
    "from shapely import wkt\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e7c6cc",
   "metadata": {},
   "source": [
    "## load variables - gabions\n",
    "- data folder\n",
    "- cleaned_df - for only gabions\n",
    "- json template\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "42db45e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'mini_projects/regreen_cleaning/brics3_migration/'\n",
      "/Users/victor/Documents/projects/mini_projects/regreen_cleaning/brics3_migration\n"
     ]
    }
   ],
   "source": [
    "cd mini_projects/regreen_cleaning/brics3_migration/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d55de868",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = os.path.join(os.getcwd(),'data')\n",
    "cleaned_csv = os.path.join(data_folder, 'final_range_data.csv')\n",
    "dff = pd.read_csv(cleaned_csv)\n",
    "\n",
    "#lambda function to filter for gabions\n",
    "#for each row, is it a list/str, then is 'gabions' in it, if so, return the df.\n",
    "cleaned_df = dff[\n",
    "    dff[\"land_use_selection-intervention\"]\n",
    "    .apply(lambda x: isinstance(x, (list, str)) and \"gabions\" in x)\n",
    "]\n",
    "\n",
    "#gabions datasets\n",
    "gabions_df = pd.read_csv(os.path.join(data_folder, 'brics_csvs', 'outputs','cleaned_Rangeland_Somalia_BRCiSIII-trees_grasses_gabions.csv'))\n",
    "\n",
    "TEMPLATE_FILE = os.path.join(data_folder,\"halfmoon_json_template.json\")\n",
    "with open(TEMPLATE_FILE, \"r\") as f:\n",
    "    template = json.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fb8896",
   "metadata": {},
   "source": [
    "## check gabions count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5769cfba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mi\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mhalfmoons gabions water_points swales gulley_plugging\u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m    \u001b[39m\u001b[38;5;247mcount\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mi\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mgabions\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mcount\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m2\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mi\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mgabions\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mcount\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m3\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mi\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mgabions\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mcount\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m4\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mi\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mgabions\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mcount\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m5\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mi\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mgabions\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mcount\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m6\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mi\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mgabions\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mcount\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m7\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mi\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mgabions\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mcount\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m8\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mgabions count\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;32mlen\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mcleaned_df\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m8\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('gabions count', 8)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = dff[\"land_use_selection-intervention\"]\n",
    "count = 0\n",
    "for idx, i in enumerate(list(x)):\n",
    "    if 'gabions' in i:\n",
    "        count += 1\n",
    "        ic(i, count)\n",
    "\n",
    "ic('gabions count',len(cleaned_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59686ff8",
   "metadata": {},
   "source": [
    "## enumerators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "548e7739",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorted(list(dff['basic_info-name'].unique()))\n",
    "##empty name and key dictionary\n",
    "names_dict = {}\n",
    "for idx, row in dff.iterrows():\n",
    "    #ic({row[\"KEY\"], row[\"basic_info-name\"]})\n",
    "    names_dict[row[\"KEY\"]] = row[\"basic_info-name\"]\n",
    "#ic(names_dict)\n",
    "name_uname_dict = {\n",
    "    \"Zakariye haji ali\": \"abdullahi.hassan@mardo.org\", \n",
    "    \"Issack Idow Ibrahim\": \"abdullahi.hassan@mardo.org\",\n",
    "    \"Abdullahi Hassan Adan\": \"abdullahi.hassan@mardo.org\",\n",
    "    \"Abdikheir Mohamed\": \"mukhtar.yusuf23\",\n",
    "    \"Abdikheir Mohamed Ali\": \"mukhtar.yusuf23\",\n",
    "    \"Abdikheir Mohamed Dahir\": \"mukhtar.yusuf23\",\n",
    "    \"Ali\": \"mukhtar.yusuf23\",\n",
    "    \"Ali Adan\": \"mukhtar.yusuf23\",\n",
    "    \"Ali Aden\": \"mukhtar.yusuf23\",\n",
    "    \"Fathi\": \"mukhtar.yusuf23\", \n",
    "    \"Fathi Abdirashid\": \"mukhtar.yusuf23\",\n",
    "    \"Ahmed Omar Hassan\": \"AhmedOmar\",\n",
    "    \"Maria Abdirahman Ali\": \"AhmedOmar\",\n",
    "    \"ABSHIR ABDULLAH ALI\": \"Ahil\",\n",
    "    \"Ahmed Ibrahim\": \"JubaFoundation\",\n",
    "    \"Ahmed Ibrahim Mohamed\": \"JubaFoundation\",\n",
    "    \"Abdiaziz Adan Hassa\": \"guudow\",\n",
    "    \"Abdiaziz Adan Hassan\": \"guudow\",\n",
    "    \"Abdi Hassan Adan\": \"AbdiHassan\",\n",
    "    \"Abdullahi\": \"sharif1234\",\n",
    "    \"Abdirashid Sheikh Mohamed\": \"NRMO\",\n",
    "    \"Abdullahi Sharif\": \"sharif1234\",\n",
    "    \"Abdullahi Sharif LLG\": \"sharif1234\",\n",
    "    \"Abdullahi Sharif Noor LLG\": \"sharif1234\",\n",
    "    \"Abdijalil\": \"Csxaashi\",\n",
    "    \"Abdijalil said\": \"Csxaashi\",\n",
    "    \"Abdikarim Mohamed Ismail\": \"samandoulgou\",\n",
    "    \"Abdikarin Mohamed Ismail\": \"samandoulgou\",\n",
    "    \"Hassan Omar Khadhib\": \"Khadhib\",\n",
    "    \"Hassan Omar Khadhibr\": \"Khadhib\",\n",
    "    \"Jamal Ali\": \"JamalAli\",\n",
    "    \"Jamal Ali Tagal\": \"JamalAli\",\n",
    "    \"Mohamud Abdullahi Ali\": \"Mohamud\",\n",
    "    \"Moulid Abdullahi Abdi\": \"Moulidwadani\",\n",
    "    \"Muktar Mohamednoor Rage\": \"Mrage1997\",\n",
    "    \"Osman Ebey Omar\": \"iibey\",\n",
    "    \"Yusuf Mahi munye\": \"Mcnbdn617660\",\n",
    "    \"abdullahi Sharif LLG\": \"sharif1234\",\n",
    "    \"osman Ebey Omar\": \"iibey\",\n",
    "}\n",
    "\n",
    "## match and replace names with usernames\n",
    "for k, v in names_dict.items():\n",
    "    for key, value in name_uname_dict.items():\n",
    "        if v == key:\n",
    "            names_dict[k] = value\n",
    "#ic(names_dict)\n",
    "\n",
    "##enumerator dictionary\n",
    "enumerator = {\n",
    "        \"id\": 3726,\n",
    "        \"first_name\": \"First\",\n",
    "        \"last_name\": \"Last\",\n",
    "        \"gender\": \"Male\",\n",
    "        \"age_category\": \"18 - 35\",\n",
    "        \"phone_number\": \"0e15704046\",\n",
    "        \"email\": \"test_mail@gmail.com\",\n",
    "        \"country\": \"test\",\n",
    "        \"organization\": \"Test\",\n",
    "        \"username\": \"test\",\n",
    "        \"type\": \"ENUMERATOR\"\n",
    "    }\n",
    "\n",
    "enums = []\n",
    "#create enumerator jsons\n",
    "for key, value in names_dict.items():\n",
    "    e = deepcopy(enumerator)\n",
    "    e['username'] = value\n",
    "    e['key'] = key\n",
    "    enums.append(e)\n",
    "\n",
    "#ic(enums)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9e60f4",
   "metadata": {},
   "source": [
    "## farming entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b58af303",
   "metadata": {},
   "outputs": [],
   "source": [
    "farming_entity_list = []\n",
    "for idx, i in enumerate(cleaned_df.to_dict(orient='records'), start=1):\n",
    "    farming_entity = {}\n",
    "    #ic(i['basic_info-organisation_name'])\n",
    "    farming_entity['id'] = idx\n",
    "    farming_entity['first_name'] = i['basic_info-organisation_name']\n",
    "    farming_entity['middle_name'] = i['basic_info-organisation_name']\n",
    "    farming_entity['last_name'] = i['basic_info-organisation_name']\n",
    "    farming_entity['organization'] = 'INSTITUTION'\n",
    "    farming_entity['key'] = i['KEY']\n",
    "    \n",
    "    farming_entity_list.append(\n",
    "        {\n",
    "            \"farmingEntity\": farming_entity, \n",
    "            'key': i['KEY']\n",
    "        }\n",
    "    )\n",
    "    #ic(farming_entity_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a2950a",
   "metadata": {},
   "source": [
    "## plot-gabions_details\n",
    "- read df to dictionary, for matching keys, extract df values\n",
    "### plot-points\n",
    "- parse the geoshape column from cleaned df\n",
    "- split and extract the values from each i\n",
    "- append to json keys\n",
    "\n",
    "## crops\n",
    "- get matching rows based on key(id)\n",
    "- for these rows if crop has crops, get its values and 'other' if any\n",
    "    - every matching rows values are appended to a list(of all crops for that plot)\n",
    "- clean 'and' from the crop types\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8e51052f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import copy\n",
    "import re\n",
    "\n",
    "plot_list = []\n",
    "point_id = 1\n",
    "\n",
    "records = cleaned_df.to_dict(orient='records')\n",
    "\n",
    "count = 0\n",
    "#iterate over every i to capture plot details\n",
    "for idx, i in enumerate(records):\n",
    "    plot_id = idx + 1\n",
    "    count += 1\n",
    "\n",
    "    # ---- BUILD PLOT DETAILS ----\n",
    "    template_cp = copy.deepcopy(template[0])\n",
    "    plot_details = template_cp['plot']\n",
    "\n",
    "    plot_details['id'] = plot_id\n",
    "    plot_details['key'] = i['KEY']\n",
    "    plot_details['name'] = uuid.uuid4().hex\n",
    "    plot_details['calculated_size'] = i['area_ha']\n",
    "    plot_details['photo_url'] = i['plot_details-photo']\n",
    "    plot_details['farmingEntityId'] = farming_entity['id']\n",
    "    plot_details['livestock_allowed'] = False if i['land_use_selection-land_use'] == 'agriculture' else True\n",
    "    plot_details['conservation_area'] = False\n",
    "\n",
    "    #get only child row for this key\n",
    "    matching_child_rows = gabions_df[gabions_df['PARENT_KEY'] == i['KEY']]\n",
    "\n",
    "    #holds every row's crops\n",
    "    all_crops = []\n",
    "    \"\"\"----------------------------------CROP STATUS ----------------------------------\"\"\"\n",
    "    #iterate over matching child is to build crop status\n",
    "    for x in pd.DataFrame(matching_child_rows).to_dict(orient='records'):\n",
    "        #ic(x['PARENT_KEY'], x[\"KEY\"], x[\"managements_gabions-crops_in_field9\"], x[\"managements_gabions-other_crops\"])\n",
    "\n",
    "        if x['managements_gabions-crops_present9'] == 'no' or pd.isna(x['managements_gabions-crops_present9']):\n",
    "            plot_details['has_crops'] = False\n",
    "        elif x['managements_gabions-crops_present9'] == 'yes':\n",
    "            plot_details['has_crops'] = True\n",
    "\n",
    "\n",
    "        #get a list of all crops in field\n",
    "        if pd.isna(x['managements_gabions-crops_in_field9']):\n",
    "            crop_list = []\n",
    "        else:\n",
    "            crop_list = str(x['managements_gabions-crops_in_field9']).split(\" \")\n",
    "            ic(crop_list, x['KEY'])\n",
    "\n",
    "\n",
    "        #check that 'other' crops exist\n",
    "        if 'other' in crop_list:\n",
    "            #split by comma or 'and'\n",
    "            other_crops_value = re.split(r',|\\band\\b', x['managements_gabions-other_crops'])\n",
    "            #strip whitespace\n",
    "            other_crops_value = [c.strip() for c in other_crops_value if c.strip()]\n",
    "\n",
    "            #get rid of 'and' if exists\n",
    "            if 'and' in other_crops_value:\n",
    "                other_crops_value.remove('and')\n",
    "\n",
    "            #only add if not empty\n",
    "            if other_crops_value != []:\n",
    "                crop_list.remove('other')\n",
    "                crop_list.extend(other_crops_value)\n",
    "                #append crop list for this row to all crops\n",
    "            all_crops.extend(crop_list)\n",
    "            ic(all_crops)\n",
    "        \n",
    "        elif 'other' not in crop_list:\n",
    "            all_crops.extend(crop_list)\n",
    "\n",
    "        plot_details['crops'] = list(set(all_crops))\n",
    "\n",
    "        \n",
    "    \"\"\"--------------------------------GEOSHAPE PARSING ----------------------------------\"\"\"\n",
    "    geoshape_str = i['plot_details-polygon']\n",
    "    \n",
    "    def parse_geoshape(geoshape_str):\n",
    "        #parse a geoshape string into a list of point dictionaries\n",
    "        points = []\n",
    "        parts = geoshape_str.split(';')\n",
    "\n",
    "        for part in parts:\n",
    "            part = part.strip()\n",
    "            if not part:\n",
    "                continue\n",
    "\n",
    "            lat, lon, alt, acc = map(float, part.split(' '))\n",
    "\n",
    "            points.append({\n",
    "                \"longitude\": lon,\n",
    "                \"latitude\": lat,\n",
    "                \"altitude\": alt,\n",
    "                \"accuracy\": acc\n",
    "            })\n",
    "\n",
    "        return points\n",
    "\n",
    "    parsed_points = parse_geoshape(geoshape_str)\n",
    "\n",
    "    points_list = []\n",
    "    for p in parsed_points:\n",
    "        points_list.append({\n",
    "            \"id\": point_id,\n",
    "            \"plotId\": plot_id,\n",
    "            \"longitude\": p[\"longitude\"],\n",
    "            \"latitude\": p[\"latitude\"],\n",
    "            \"altitude\": p[\"altitude\"],\n",
    "            \"accuracy\": p[\"accuracy\"]\n",
    "        })\n",
    "        point_id += 1\n",
    "\n",
    "\n",
    "    \"\"\"--------------------------------ADMINISTRATIVE DETAILS ----------------------------------\"\"\"\n",
    "    administrative = plot_details['subCounty']\n",
    "    administrative['subcounty_name'] = i['geography-district_name']\n",
    "    administrative['county']['county_name'] = i['geography-region_name']\n",
    "\n",
    "\n",
    "    #update plot_details with number of points and administrative info\n",
    "    plot_details['points'] = points_list\n",
    "    plot_details['subCounty'] = administrative\n",
    "    \n",
    "    # del plot_details['points']\n",
    "    # del plot_details['subCounty']\n",
    "    general_plot = {\n",
    "        \"plot\":plot_details, \n",
    "        'key':i['KEY']\n",
    "    }\n",
    "    #ic(i['KEY'])\n",
    "    plot_list.append(\n",
    "        general_plot\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fca58b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nan']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(os.path.join(data_folder, 'to_delete.json'), 'w') as f:\n",
    "    json.dump(plot_list, f, indent=4)\n",
    "\n",
    "str(gabions_df['managements_gabions-crops_in_field9'][0]).split(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4633b5",
   "metadata": {},
   "source": [
    "# project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d983a2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;32mset\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mnames\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;245m{\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mBRCiS III\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m}\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BRCiS III'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projects_list = []\n",
    "\n",
    "names =[]\n",
    "for row in cleaned_df.to_dict(orient='records'):\n",
    "    name = row['land_use_selection-project_name']\n",
    "    \n",
    "\n",
    "    if name == 'terra':\n",
    "        name = name.upper()\n",
    "        id = 131\n",
    "    elif name == 'brcis3':\n",
    "        name = 'BRCiS III'\n",
    "        id = 93\n",
    "    names.extend([name])\n",
    "    projects_list.append({\n",
    "        \"project\": {\n",
    "            \"id\": id,\n",
    "            \"project_name\": name\n",
    "        },\n",
    "        \"key\": row['KEY']\n",
    "    })\n",
    "\n",
    "ic(set(names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def1e088",
   "metadata": {},
   "source": [
    "## gabions \n",
    "missing \n",
    "- herbacious cover\n",
    "- who manages >> used who established\n",
    "- erosion type\n",
    "- is_intervention_effective\n",
    "- vertical_spacing\n",
    "- horizontal_spacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ec982903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 8 - no child recs 7 =  1 with kids\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mc\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m\"\u001b[39m\u001b[38;5;36mKEY\u001b[39m\u001b[38;5;36m\"\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36muuid:7f209d1a-995b-4b0d-aed3-6d832c69b9a5\u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m    \u001b[39m\u001b[38;5;32mlen\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mgabions_child_list\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m6\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mno child rows for\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mno child rows for\u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m    \u001b[39m\u001b[38;5;247mc\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mKEY\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36muuid:c057a054-841a-47b7-9a73-323edc2aa97f\u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mno child rows for\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mno child rows for\u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m    \u001b[39m\u001b[38;5;247mc\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mKEY\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36muuid:462595d8-2d63-4d31-a8d2-d9558f2cf792\u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mno child rows for\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mno child rows for\u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m    \u001b[39m\u001b[38;5;247mc\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mKEY\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36muuid:d04f0fa4-3d5e-4a54-884c-206853b0db20\u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mno child rows for\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mno child rows for\u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m    \u001b[39m\u001b[38;5;247mc\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mKEY\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36muuid:ebb84261-cb61-4373-a49b-5143ebc771a1\u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mno child rows for\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mno child rows for\u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m    \u001b[39m\u001b[38;5;247mc\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mKEY\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36muuid:c1703221-8e2a-4e5b-9c4b-6ea19acd86de\u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mno child rows for\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mno child rows for\u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m    \u001b[39m\u001b[38;5;247mc\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mKEY\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36muuid:7f7994f6-e4e6-4136-b881-0bc16590284c\u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mno child rows for\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mno child rows for\u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m    \u001b[39m\u001b[38;5;247mc\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mKEY\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36muuid:1d046361-3a8b-433d-99d7-b6a103beab88\u001b[39m\u001b[38;5;36m'\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "gabions_no_children = []\n",
    "gabions_econtrol = []\n",
    "\n",
    "#dictionary to map odk values to RA app schema values\n",
    "mapping_dict = {\n",
    "    \"STICKS_BRANCH\":\"STICKS_PROTECTION\",\n",
    "    \"DEBRIS_REMOVAL\":\"DEBRIS_REMOVAL\",\n",
    "    \"INVASIVE_SPECIES\":\"INVASIVE_CONTROL\",\n",
    "    \"WEEDING\":\"WEEDING\",\n",
    "    \"WATERING\":\"WATERING\",\n",
    "    \"PLANTING_SEEDLING\":\"PLANTING_ANNUAL_PERENNIAL_CROPS\"\n",
    "}\n",
    "\n",
    "\n",
    "for idx, c in enumerate(records):\n",
    "\n",
    "    cureent_status_list = []\n",
    "    all_grasses = []\n",
    "    all_trees = []\n",
    "    gabions_child_list = []\n",
    "\n",
    "\n",
    "    \"\"\"-----------------------------------gabions DETAILS-------------------------------------\"\"\"\n",
    "    # collect row gabion details, will be used to create list of gabion detail+current status for each repeating record\n",
    "    parent_base_gabions_details = {\n",
    "        \"id\": idx + 1,\n",
    "        \"key\":c[\"KEY\"],\n",
    "        \"erosion_control_type\": \"Gabions\",\n",
    "        \"established_date\": datetime.strptime(c['gabions-gabions_details-date'], \"%d/%m/%Y\").strftime(\"%Y-%m\"),\n",
    "        \"material_used\": [\n",
    "            \"Rocks\"\n",
    "        ],\n",
    "        \"other_material_used\": \"\",\n",
    "        \"who_established\": [\"MALE\", \"FEMALE\"] if c[\"gabions-gabions_details-manages\"] == 'both' else \"MALE\" if c[\"gabions-gabions_details-manages\"]==\"male\" else [],\n",
    "        \"other_who_established\": \"YOUTH\" if c[\"gabions-gabions_details-youth_manages\"] == 'yes' else \"\",\n",
    "        \"total_interventions\": c[\"gabions-gabions_details-total\"],\n",
    "        \"length\": c[\"gabions-gabions_details-length\"],\n",
    "        \"width\": c[\"gabions-gabions_details-width\"],\n",
    "        \"depth\": c[\"gabions-gabions_details-depth\"],\n",
    "        \"vertical_spacing\": 0,\n",
    "        \"horizontal_spacing\": 0,\n",
    "        \"labor_payment\": c[\"gabions-gabions_details-paid_unpaid_labor\"],        \n",
    "        # \"has_grass\": any(grass_present),\n",
    "        # \"total_number_grasses_planted\": total_num_grasses_planted,\n",
    "        # \"kg_grass_seeds_planted\": total_kg_grass_seeds,\n",
    "        # \"has_trees\": any(trees_present),\n",
    "        # \"total_number_different_trees_planted\": total_num_tree_species,\n",
    "        # \"total_number_trees_planted\": total_num_trees_planted,\n",
    "        # \"total_number_trees_survived\": total_num_trees_survived,\n",
    "        # \"management_practices\":  [v for k, v in mapping_dict.items() if k in mngmts] + ([\"OTHER\"] if any(k not in mapping_dict.keys() for k in mngmts) else []),\n",
    "        # \"other_managements\": \" \".join([c for c in mngmts if c not in mapping_dict.keys()]),\n",
    "        \"usages\":[\"MIGRATED_NOT_KNOWN\"],\n",
    "        \"other_usages\": \"\",\n",
    "        \"rangelandEntryId\": 2\n",
    "        # \"currentStatus\": cureent_status_list,\n",
    "        # \"grassEstablishment\": all_grasses,\n",
    "        # \"treeEstablishment\":all_trees   \n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "    #if c['KEY'] == \"uuid:1975a725-83a5-4bdd-8305-35ac65b2cce9\":\n",
    "    \"\"\"-----------------------------------gabions CHILD DETAILS-------------------------------------\"\"\"\n",
    "\n",
    "    #for every record, get the matching child rows\n",
    "    matching_child_rows = gabions_df[gabions_df['PARENT_KEY'] == c['KEY']]\n",
    "\n",
    "\n",
    "    total_num_grasses_planted = 0\n",
    "    total_kg_grass_seeds = 0.0\n",
    "    total_num_tree_species = 0\n",
    "    total_num_trees_planted = 0\n",
    "    total_num_trees_survived = 0\n",
    "    grass_present = []\n",
    "    trees_present = []\n",
    "    mngmts = []\n",
    "    \n",
    "    \"\"\"-------------------------non-child details records extraction-------------------------\"\"\"\n",
    "    #for rows with no child rows, create a default current status, add base parent details\n",
    "    if matching_child_rows.empty:\n",
    "        ic('no child rows for', c['KEY'])\n",
    "        centroid = wkt.loads(c[\"geometry\"]).centroid\n",
    "        currentStatus = {\n",
    "            \"id\": idx + 1,\n",
    "            \"key\": c[\"KEY\"],\n",
    "            \"herbaceous_cover\": \"ABSENT\",\n",
    "            \"visible_erosion\": False,\n",
    "            \"erosion_type\": [],\n",
    "            \"other_erosion_type\": \"\",\n",
    "            \"is_intervention_effective\": False,\n",
    "            \"longitude\": centroid.x,\n",
    "            \"latitude\": centroid.y,\n",
    "            \"altitude\": 0,\n",
    "            \"accuracy\": 0,\n",
    "            \"photo_url\": \"test.jpg\",\n",
    "            \"comments\": f\"state {c['geography-state_name']} community {c['geography-community_name']}\",\n",
    "            \"econtrolId\": 1,\n",
    "            \"grassCurrentStatus\": [],\n",
    "            \"treeCurrentStatus\": []\n",
    "        }\n",
    "        gabions_details = {\n",
    "            **parent_base_gabions_details,\n",
    "            \"has_grass\": True if total_num_grasses_planted > 0 else False,\n",
    "            \"total_number_grasses_planted\": total_num_grasses_planted,\n",
    "            \"kg_grass_seeds_planted\": total_kg_grass_seeds,\n",
    "            \"has_trees\": True if total_num_trees_planted > 0 else False,\n",
    "            \"total_number_different_trees_planted\": total_num_tree_species,\n",
    "            \"total_number_trees_planted\": total_num_trees_planted,\n",
    "            \"total_number_trees_survived\": total_num_trees_survived,\n",
    "            \"management_practices\":  [v for k, v in mapping_dict.items() if k in mngmts] + ([\"OTHER\"] if any(k not in mapping_dict.keys() for k in mngmts) else []),\n",
    "            \"other_managements\": \" \".join([c for c in mngmts if c not in mapping_dict.keys()]),\n",
    "            \"currentStatus\": currentStatus,\n",
    "            \"grassEstablishment\": [],\n",
    "            \"treeEstablishment\": []\n",
    "        }\n",
    "\n",
    "        gabions_no_children.append(gabions_details)\n",
    "        #exit the child loop\n",
    "        continue\n",
    "    \n",
    "    idxx =0\n",
    "    for x in matching_child_rows.to_dict(orient='records'):\n",
    "\n",
    "        total_num_grasses_planted = 0 if pd.isna(x[\"grass_gabions-num_grass_species\"]) else x[\"grass_gabions-num_grass_species\"]\n",
    "        total_kg_grass_seeds = 0 if pd.isna(x[\"grass_gabions-kg_grass_seeds\"]) else x[\"grass_gabions-kg_grass_seeds\"]\n",
    "        total_num_tree_species = 0 if pd.isna(x[\"tree_gabion-num_tree_species\"]) else x[\"tree_gabion-num_tree_species\"]\n",
    "        total_num_trees_planted = 0 if pd.isna(x[\"tree_gabion-num_trees_planted\"]) else x[\"tree_gabion-num_trees_planted\"]\n",
    "        total_num_trees_survived = 0 if pd.isna(x[\"tree_gabion-num_tree_survived\"]) else x[\"tree_gabion-num_tree_survived\"]\n",
    "        grass_present.append(True if str(x[\"tree_gabion-planted_choice9\"]).strip() in [\"both\", \"grasses\"] else False)\n",
    "        trees_present.append(True if str(x[\"tree_gabion-planted_choice9\"]).strip() in [\"both\", \"trees\"] else False)\n",
    "        mngmts.extend(str(x[\"managements_gabions-management_practices\"]).upper().split()) if not pd.isna(x[\"managements_gabions-management_practices\"]) else 'NAN'\n",
    "\n",
    "        \n",
    "        if pd.notna(x['gps-Longitude']):\n",
    "            child_coords = {\n",
    "                \"longitude\": x[\"gps-Longitude\"],\n",
    "                \"latitude\" : x['gps-Latitude'],\n",
    "                \"altitude\" : x[\"gps-Altitude\"],\n",
    "                \"accuracy\" : x[\"gps-Accuracy\"],\n",
    "                \"photo_url\": x[\"photo\"],\n",
    "                \"comments\" : f\"agric_field_state {x[\"managements_gabions-agricultural_field_state\"] if pd.notna(x[\"managements_gabions-agricultural_field_state\"]) else \"MIGRATED_NOT_KNOWN\"}\"\n",
    "            }\n",
    "                \n",
    "\n",
    "        \"\"\"--------------TREE ESTABLISHMENT-------------\"\"\"\n",
    "        tree_status_list = []\n",
    "        #no trees\n",
    "        grass_status_list = []\n",
    "        \"\"\"---------------GRASS_ESTABLISHMENT------------\"\"\"\n",
    "        #no grasses\n",
    "       \n",
    "        \"\"\"--------------------CURRENT STATUS--------------------\"\"\"\n",
    "        idxx += 1\n",
    "        comms = f\" state {c['geography-state_name'].replace(\"â€¦\", \"\").replace(\".\", \"\").replace(\"..\", \"\")} community {c['geography-community_name']}\"\n",
    "        currentStatus= {\n",
    "            \"id\": idxx,\n",
    "            \"key\":c[\"KEY\"],            \n",
    "            \"herbaceous_cover\": \"ABSENT\",\n",
    "            \"visible_erosion\": False,\n",
    "            \"erosion_type\": [\n",
    "            ],\n",
    "            \"other_erosion_type\": \"NONE\",\n",
    "            \"is_intervention_effective\": True,\n",
    "            \"longitude\": child_coords[\"longitude\"] if child_coords else wkt.loads(c[\"geometry\"]).centroid.x,\n",
    "            \"latitude\": child_coords[\"latitude\"]  if child_coords else wkt.loads(c[\"geometry\"]).centroid.y,\n",
    "            \"altitude\": child_coords[\"altitude\"]  if child_coords else 0,\n",
    "            \"accuracy\": child_coords[\"accuracy\"]  if child_coords else 0,\n",
    "            \"photo_url\": child_coords[\"photo_url\"] if child_coords else 'test.jpg',\n",
    "            \"comments\": child_coords[\"comments\"] + comms if child_coords else comms,\n",
    "            \"econtrolId\": 1,\n",
    "            \"grassCurrentStatus\":grass_status_list,\n",
    "            \"treeCurrentStatus\":tree_status_list\n",
    "        }\n",
    "        \n",
    "        #add every status to the to serve as establishment        \n",
    "        all_grasses.extend(grass_status_list)\n",
    "\n",
    "        ## update establishment grasses and trees with econtrol_id key\n",
    "        establishment_grasses = []\n",
    "        for i in enumerate(all_grasses):\n",
    "            data = dict(i[1])\n",
    "            data['econtrol_id'] = data.pop('econtrol_status_id')\n",
    "            establishment_grasses.append(data)\n",
    "        \n",
    "\n",
    "        establishment_trees = []\n",
    "        for i in enumerate(all_trees):\n",
    "            data = dict(i[1])\n",
    "            data['econtrol_id'] = data.pop('econtrol_status_id')\n",
    "            establishment_trees.append(data)\n",
    "            \n",
    "\n",
    "        gabions_details = {\n",
    "            **parent_base_gabions_details,\n",
    "            \"has_grass\": True if total_num_grasses_planted > 0 else False,\n",
    "            \"total_number_grasses_planted\": total_num_grasses_planted,\n",
    "            \"kg_grass_seeds_planted\": total_kg_grass_seeds,\n",
    "            \"has_trees\": True if total_num_trees_planted > 0 else False,\n",
    "            \"total_number_different_trees_planted\": total_num_tree_species,\n",
    "            \"total_number_trees_planted\": total_num_trees_planted,\n",
    "            \"total_number_trees_survived\": total_num_trees_survived,\n",
    "            \"management_practices\":  [v for k, v in mapping_dict.items() if k in mngmts] + ([\"OTHER\"] if any(k not in mapping_dict.keys() for k in mngmts) else []),\n",
    "            \"other_managements\": \" \".join([c for c in mngmts if c not in mapping_dict.keys()]),\n",
    "            \"currentStatus\": currentStatus,\n",
    "            \"grassEstablishment\": establishment_grasses,\n",
    "            \"treeEstablishment\": establishment_trees   \n",
    "        }\n",
    "\n",
    "        gabions_child_list.append(gabions_details)\n",
    "    \n",
    "    if gabions_child_list:\n",
    "        ic(c[\"KEY\"], len(gabions_child_list))\n",
    "        gabions_econtrol.append(\n",
    "            {\n",
    "                \"econtrol\": gabions_child_list,\n",
    "                \"key\": c['KEY']\n",
    "            }\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Total {len(cleaned_df)} - no child recs {len(gabions_no_children)} =  {len(cleaned_df)- len(gabions_no_children)} with kids\" )\n",
    "gabions_econtrol.extend([{\"econtrol\": [i], \"key\" :i[\"key\"]} for i in gabions_no_children])\n",
    "\n",
    "#add child list details to overal gabions_econtrol\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d463b75",
   "metadata": {},
   "source": [
    "If a parent has 4 repeats, reproduce the parent 4 time s "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "55f65860",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_folder, 'to_delete.json'), 'w') as f:\n",
    "    json.dump(gabions_econtrol, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5700a87b",
   "metadata": {},
   "source": [
    "## merge components into one json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "24d098fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;32mlen\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mlst\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m8\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;32mlen\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mlst\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m8\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;32mlen\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mlst\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m8\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;32mlen\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mlst\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m8\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;32mlen\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mfinal\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m8\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# component lists\n",
    "lists = [farming_entity_list, gabions_econtrol, plot_list, projects_list]\n",
    "\n",
    "# The output dictionary\n",
    "merged = {}\n",
    "\n",
    "for lst in lists:\n",
    "    ic(len(lst))\n",
    "    for item in lst:\n",
    "        k = item['key']\n",
    "\n",
    "        #check if already updated\n",
    "        if k not in merged:\n",
    "            merged[k] = {}\n",
    "            \n",
    "        #merge the item into the existing dictionary\n",
    "        merged[k].update(item)\n",
    "\n",
    "final = list(merged.values())\n",
    "for i in final:\n",
    "    #match enumerators\n",
    "    for l in enums:\n",
    "        if i['key'] == l['key']:\n",
    "            i['enumerator'] = l\n",
    "\n",
    "\n",
    "    i[\"boma\"] = []\n",
    "    i[\"cgrazing\"] = []\n",
    "    i[\"microcatchment\"]= []\n",
    "    i[\"seedbank\"] = []\n",
    "    i[\"seeding\"] = []\n",
    "    i[\"waterpoint\"] = []\n",
    "    i[\"completed\"] = True\n",
    "    i[\"iremoval\"] = []\n",
    "    i[\"rangeModuleId\"] = 1\n",
    "    i[\"currentStep\"]= \"DONE\"\n",
    "    i[\"moduleId\"] = 6\n",
    "    i[\"is_revisit\"] = False\n",
    "    #get the date_collected\n",
    "    for j in records:\n",
    "        if i[\"key\"] == j[\"KEY\"]:\n",
    "            i[\"date_collected\"] = datetime.strptime(j['basic_info-date'], \"%d/%m/%Y\").strftime(\"%Y-%m-%d\")\n",
    "    #match project id\n",
    "    for x in projects_list:\n",
    "        if i['key'] == x['key']:\n",
    "            i['projectId'] = x['project']['id']\n",
    "    #match plot id\n",
    "    for k in plot_list:\n",
    "        if i['key'] == k['key']:\n",
    "            i['plotId'] = k['plot']['id']\n",
    "    #match farming_entity_id\n",
    "    for h in farming_entity_list:\n",
    "        if i['key'] == h['key']:\n",
    "            i['farmingEntityId'] = h['farmingEntity']['id']\n",
    "    #match enumerator id\n",
    "    for e in enums:\n",
    "        if i['key'] == e['key']:\n",
    "            i['enumeratorId'] = e['id']\n",
    "\n",
    "\n",
    "ic(len(final))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1a2aa238",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_folder, 'to_delete.json'), 'w') as f:\n",
    "    json.dump(final, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5219fd",
   "metadata": {},
   "source": [
    "## clean up keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "34176c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean up keys\n",
    "def remove_keys(obj, key=\"key\"):\n",
    "    if isinstance(obj, dict):\n",
    "        obj.pop(key, None)\n",
    "        for v in obj.values():\n",
    "            remove_keys(v, key)\n",
    "    elif isinstance(obj, list):\n",
    "        for v in obj:\n",
    "            remove_keys(v, key)\n",
    "    return obj\n",
    "\n",
    "finaal = [x for x in final if x['key'] == 'uuid:b4a2d545-66fe-4d23-825b-41025149b460']\n",
    "finaal = [remove_keys(i) for i in final]\n",
    "\n",
    "#add id\n",
    "for idx, c in enumerate(finaal):\n",
    "    c['id'] = idx + 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "38e7a1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_folder, 'to_delete.json'), 'w') as f:\n",
    "    json.dump(finaal, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d38b5f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36m✅\u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36m✅\u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36m✅\u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36m✅\u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36m✅\u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36m✅\u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36m✅\u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36m✅\u001b[39m\u001b[38;5;36m'\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "for i in enumerate(finaal):\n",
    "    if len(i[1].keys()) != 23:\n",
    "        ic(\"ERROR\")\n",
    "    else:\n",
    "        ic(\"✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbd3019",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e662df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1e028e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
